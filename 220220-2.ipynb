{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a70f48",
   "metadata": {},
   "source": [
    "# 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1091652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n",
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "# 어제 한 부분이지만 오늘 코드를 돌리기 위해 가져옴\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
    "\n",
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "print(sentences)\n",
    "\n",
    "vocab = {}\n",
    "preprocessed_sentences = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for sentence in sentences:\n",
    "    # 단어 토큰화\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "    result = []\n",
    "    for word in tokenized_sentence:\n",
    "        word = word.lower()    # 모든 단어를 소문자화하여 단어의 개수를 줄인다\n",
    "        if word not in stop_words:    # 단어 토큰화 된 결과에 대해서 불용어를 제거한다\n",
    "            if len(word) > 2:    # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거한다\n",
    "                result.append(word)\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 0\n",
    "                vocab[word] += 1    # {'barber', 1} barber가 나올수록 숫자 증가\n",
    "    preprocessed_sentences.append(result)\n",
    "print(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3904700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "preprocessed_sentences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# fit_on_texts() 안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)\n",
    "\n",
    "# 문장이 가장 긴게 뭔지 출력\n",
    "max_len = max(len(item) for item in encoded)\n",
    "print(max_len)\n",
    "\n",
    "# 문장의 길이를 가장 긴 문장의 길이로 맞춰줌\n",
    "for sentence in encoded:    # 각 문장에 대해서\n",
    "    while len(sentence) < max_len:    # max_len보다 작으면\n",
    "        sentence.append(0)\n",
    "        \n",
    "padded_np = np.array(encoded)\n",
    "padded_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7da63220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)\n",
    "\n",
    "padded = pad_sequences(encoded)    # 앞쪽에 0을 채움\n",
    "padded\n",
    "\n",
    "padded = pad_sequences(encoded, padding = 'post')    # 뒤에 0을 채움\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dfd0ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(padded == padded_np).all()    # 케라스와 코딩을 이용한 패딩의 결과는 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12cf8c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터가 손실될 경우 앞의 단어가 사라진다\n",
    "padded = pad_sequences(encoded, padding = 'post', maxlen=5)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b10659ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터가 손실될 경우 뒤의 단어가 사라지게 하는 코드 truncating='post'\n",
    "padded = pad_sequences(encoded, padding = 'post', truncating = 'post', maxlen=5)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87bf8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "last_value = len(tokenizer.word_index) + 1    # 단어 집합의 크기보다 1 큰 숫자 사용\n",
    "print(last_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3690427a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 14, 14, 14, 14, 14],\n",
       "       [ 1,  8,  5, 14, 14, 14, 14],\n",
       "       [ 1,  3,  5, 14, 14, 14, 14],\n",
       "       [ 9,  2, 14, 14, 14, 14, 14],\n",
       "       [ 2,  4,  3,  2, 14, 14, 14],\n",
       "       [ 3,  2, 14, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  2, 14, 14, 14, 14],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13, 14, 14, 14]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈 공간을 단어 집합의 크기보다 1 큰 숫자로 채운다\n",
    "padded = pad_sequences(encoded, padding = 'post', value = last_value)\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae8c2f",
   "metadata": {},
   "source": [
    "# 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a905626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt =Okt()\n",
    "token = okt.morphs(\"나는 자연어 처리를 배운다\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9d68275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰에 인덱스 부여\n",
    "word2index = {}\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3edb4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫벡터를 만들어 주는 함수\n",
    "def one_hot_encoding(word, word2index):\n",
    "    one_hot_vector = [0] * (len(word2index))\n",
    "    index = word2index[word]\n",
    "    one_hot_vector[index] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f31ad73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\", word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ce5d9",
   "metadata": {},
   "source": [
    "## 케라스를 이용한 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7098d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])    # 비중이 많은 순서대로 정렬\n",
    "print(tokenizer.word_index)    # 각 단어에 대한 인코딩 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9035d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 1, 6, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
    "encoded = tokenizer.texts_to_sequences([sub_text])[0]    # sub_text의 단어를 위의 번호에 맞춰서 출력\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "398f3b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical(encoded)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410eb4e",
   "metadata": {},
   "source": [
    "# 데이터의 분리\n",
    "## 지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec65410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split    # 문제와 답의 묶음에서 train과 test영역 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d2fa6",
   "metadata": {},
   "source": [
    "## X와 Y 분리하기\n",
    "### 1. zip 함수를 이용하여 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "390400b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "x, y = zip(['a', 1], ['b', 2], ['c', 3])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30ff0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "sequences = [['a', 1], ['b', 2], ['c', 3]]    # 리스트의 리스트 또는 행렬 또는 뒤에서 배울 개념인 2D텐서\n",
    "x, y = zip(*sequences)    # *를 추가\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae807c",
   "metadata": {},
   "source": [
    "### 2. 데이터프레임을 이용하여 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8befe2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>메일 본문</th>\n",
       "      <th>스팸 메일 유무</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당신에게 드리는 마지막 혜택!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내일 뵐 수 있을지 확인 부탁드...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>도연씨. 잘 지내시죠? 오랜만입...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(광고) AI로 주가를 예측할 수 있다!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    메일 본문  스팸 메일 유무\n",
       "0        당신에게 드리는 마지막 혜택!         1\n",
       "1    내일 뵐 수 있을지 확인 부탁드...         0\n",
       "2    도연씨. 잘 지내시죠? 오랜만입...         0\n",
       "3  (광고) AI로 주가를 예측할 수 있다!         1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values = [['당신에게 드리는 마지막 혜택!', 1],\n",
    "['내일 뵐 수 있을지 확인 부탁드...', 0],\n",
    "['도연씨. 잘 지내시죠? 오랜만입...', 0],\n",
    "['(광고) AI로 주가를 예측할 수 있다!', 1]]\n",
    "columns = ['메일 본문', '스팸 메일 유무']\n",
    "\n",
    "df = pd.DataFrame(values, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f55f69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 데이터 : ['당신에게 드리는 마지막 혜택!', '내일 뵐 수 있을지 확인 부탁드...', '도연씨. 잘 지내시죠? 오랜만입...', '(광고) AI로 주가를 예측할 수 있다!']\n",
      "y 데이터 : [1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x = df['메일 본문']\n",
    "y = df['스팸 메일 유무']\n",
    "\n",
    "print('x 데이터 :', x.to_list())\n",
    "print('y 데이터 :', y.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb04d6",
   "metadata": {},
   "source": [
    "### 3. Numpy를 이용하여 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e420b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.arange(0, 16).reshape((4, 4))\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9652f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 데이터 :\n",
      "[[ 0  1  2]\n",
      " [ 4  5  6]\n",
      " [ 8  9 10]\n",
      " [12 13 14]]\n",
      "y 데이터 : [ 3  7 11 15]\n"
     ]
    }
   ],
   "source": [
    "x = np_array[:, :3]\n",
    "y = np_array[:, 3]\n",
    "\n",
    "print(\"x 데이터 :\")\n",
    "print(x)\n",
    "print(\"y 데이터 :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd98fd",
   "metadata": {},
   "source": [
    "### 4. 사이킷 런을 이용하여 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f58924f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  5  6]\n",
      " [ 8  9 10]\n",
      " [12 13 14]]\n",
      "[[0 1 2]]\n",
      "[ 7 11 15]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "# test_size=0.2 : test 데이터는 전체 데이터의 20%\n",
    "# random_state는 어떤 값을 줘도 되지만 한번 준 값과 동일한 값을 줘야 한다\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "900fa40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 실습을 위해 임의로 x와 y가 이미 분리 된 데이터를 생성\n",
    "x, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "\n",
    "print(x)\n",
    "print(list(y))    # 레이블 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "367e7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 3분의 1만 test 데이터로 지정\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1234)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43431362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 9]\n",
      " [0 1]\n",
      " [6 7]]\n",
      "[[4 5]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# random_state의 값이 같으면 랜덤하게 돌려도 결과는 같지만,\n",
    "# random_State의 숫자를 다르게 넣으면 다른 값이 나온다\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d2c4a",
   "metadata": {},
   "source": [
    "## 테스트 데이터 분리하기\n",
    "### 수동으로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a59f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 실습을 위해 임의로 x와 y가 이미 분리 된 데이터를 생성\n",
    "x, y = np.arange(0, 24).reshape((12, 2)), range(12)\n",
    "print(x)\n",
    "print(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb682611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "num_of_train = int(len(x) * 0.8)   # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다\n",
    "num_of_test = int(len(x) - num_of_train)    # 전체 길이에서 80%에 해당하는 길이를 뺀다\n",
    "\n",
    "print(num_of_train)\n",
    "print(num_of_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "344e1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x[num_of_train:]    # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
    "y_test = y[num_of_train:]\n",
    "x_train = x[:num_of_train]    # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
    "y_train = y[:num_of_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bf920c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "[9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83f463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
