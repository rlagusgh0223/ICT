{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452c9955",
   "metadata": {},
   "source": [
    "# 한국어 전처리 패키지\n",
    "## PyKoSpacing\n",
    "한국어 띄어쓰기 안 되있으면 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72213e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
      "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to c:\\users\\owner\\appdata\\local\\temp\\pip-req-build-q__ej9_h\n",
      "Collecting tensorflow==2.5.3\n",
      "  Downloading tensorflow-2.5.3-cp38-cp38-win_amd64.whl (428.2 MB)\n",
      "Collecting h5py==3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting argparse>=1.4.0\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from h5py==3.1.0->pykospacing==0.5) (1.20.1)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.2.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting numpy>=1.17.5\n",
      "  Using cached numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (3.7.4.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (3.19.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (0.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorflow==2.5.3->pykospacing==0.5) (1.12.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (52.0.0.post20210125)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.3->pykospacing==0.5) (3.2.0)\n",
      "Building wheels for collected packages: pykospacing\n",
      "  Building wheel for pykospacing (setup.py): started\n",
      "  Building wheel for pykospacing (setup.py): finished with status 'done'\n",
      "  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2268593 sha256=981e85cb9cf30159b045db9a1d6a4f55d40b1381de9df9eb2aef403f2c035935\n",
      "  Stored in directory: C:\\Users\\Owner\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1qjp5nnq\\wheels\\79\\a0\\33\\16f2cd03d21f76a663f5d69a0b96f0351335385349136fbd03\n",
      "Successfully built pykospacing\n",
      "Installing collected packages: numpy, grpcio, tensorflow-estimator, keras-nightly, h5py, gast, flatbuffers, tensorflow, argparse, pykospacing\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.43.0\n",
      "    Uninstalling grpcio-1.43.0:\n",
      "      Successfully uninstalled grpcio-1.43.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "Successfully installed argparse-1.4.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 pykospacing-0.5 tensorflow-2.5.3 tensorflow-estimator-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git 'C:\\Users\\Owner\\AppData\\Local\\Temp\\pip-req-build-q__ej9_h'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e30b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
     ]
    }
   ],
   "source": [
    "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
    "\n",
    "new_sent = sent.replace(\" \", '')    # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "print(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea13254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(new_sent)\n",
    "\n",
    "print(sent)\n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092953c",
   "metadata": {},
   "source": [
    "## Py-Hanspell\n",
    "네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2317a71a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ssut/py-hanspell.git\n",
      "  Cloning https://github.com/ssut/py-hanspell.git to c:\\users\\owner\\appdata\\local\\temp\\pip-req-build-klinm1de\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\anaconda3\\lib\\site-packages (from py-hanspell==1.1) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->py-hanspell==1.1) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->py-hanspell==1.1) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->py-hanspell==1.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\owner\\anaconda3\\lib\\site-packages (from requests->py-hanspell==1.1) (1.26.4)\n",
      "Building wheels for collected packages: py-hanspell\n",
      "  Building wheel for py-hanspell (setup.py): started\n",
      "  Building wheel for py-hanspell (setup.py): finished with status 'done'\n",
      "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4894 sha256=7300fa920a117cf41ccf5509d7fdd9dfd8aa336281e60f1941c14ae66c304af1\n",
      "  Stored in directory: C:\\Users\\Owner\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-qj0gymog\\wheels\\3f\\a5\\73\\e4d2806ae141d274fdddaabf8c0ed79be9357d36bfdc99e4b4\n",
      "Successfully built py-hanspell\n",
      "Installing collected packages: py-hanspell\n",
      "Successfully installed py-hanspell-1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/ssut/py-hanspell.git 'C:\\Users\\Owner\\AppData\\Local\\Temp\\pip-req-build-klinm1de'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/ssut/py-hanspell.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2276a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지\"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a644ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 0\n",
      "틀리면 0\n",
      "왜 1\n",
      "안돼? 1\n",
      "쓰고 1\n",
      "싶은 1\n",
      "대로 1\n",
      "쓰면 1\n",
      "되지 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in spelled_sent.words.items():\n",
    "    print(key, value)\n",
    "# 0 -문제 없음\n",
    "# 1 - 맞춤법 틀림\n",
    "# 2 - 띄어쓰기 틀림\n",
    "# 3 - 표준어 아님\n",
    "# 4 - 통계적 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb01ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는 극 중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연제(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
     ]
    }
   ],
   "source": [
    "spelled_sent = spell_checker.check(new_sent)\n",
    "hanspell_sent = spelled_sent.checked\n",
    "\n",
    "print(hanspell_sent)    # 밑의 kospacing_sent와 조금 다르다 (극 중 / 극중)\n",
    "print(kospacing_sent)    # 앞서 사용한 kospacing 패키지에서 얻은 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3deec",
   "metadata": {},
   "source": [
    "# 다양한 단어의 표현 방법\n",
    "- 국소 표현 방법(이산 표현) : 각 단어별 검사(뉘앙스 파악 불가)\n",
    "- 분산 표현 방법(연속 표현) : 해당 단어 확인을 위해 주변 단어도 확인(뉘앙스 파악 가능)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84245739",
   "metadata": {},
   "source": [
    "# Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e100e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt = Okt()\n",
    "\n",
    "# 정규 표현식을 통해 온점을 제거하는 정제 작업\n",
    "token = re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")\n",
    "\n",
    "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에다가 넣음\n",
    "token = okt.morphs(token)\n",
    "\n",
    "word2index = {}\n",
    "bow = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5f5cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    }
   ],
   "source": [
    "for voca in token:\n",
    "    # token을 읽으면서, word2index에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "        # BoW 전체에 전부 기본값 1을 넣는다\n",
    "        bow.insert(len(word2index)-1, 1)    # len(word2index)-1번째 인덱스에 1을 넣어라\n",
    "    else:\n",
    "        # 재등장하는 단어의 인덱스\n",
    "        index = word2index.get(voca)\n",
    "        \n",
    "        # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다\n",
    "        bow[index] = bow[index]+1\n",
    "        \n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0488985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bag_of_words(document):\n",
    "    # 온점 제거 및 형태소 분석\n",
    "    document = document.replace('.', '')\n",
    "    tokenized_document = okt.morphs(document)\n",
    "    print(tokenized_document)\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    word_to_index = {}\n",
    "    bow = []\n",
    "    \n",
    "    for word in tokenized_document:\n",
    "        if word not in word_to_index.keys():\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            # BoW에 전부 기본값 1을 넣는다\n",
    "            bow.insert(len(word_to_index)-1, 1)\n",
    "        else:\n",
    "            # 재등장하는 단어의 인덱스\n",
    "            index = word_to_index.get(word)\n",
    "            # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다(위의 조건문에서 다 1을 넣어줬다 거기서 시작)\n",
    "            bow[index] = bow[index] + 1\n",
    "            \n",
    "    return word_to_index, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "755fb5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']\n",
      "------------------\n",
      "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "bag of words vector : [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
    "vocab, bow = build_bag_of_words(doc1)\n",
    "print(\"vocabulary :\", vocab)\n",
    "print(\"bag of words vector :\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe038bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['소비자', '는', '주로', '소비', '하는', '상품', '을', '기준', '으로', '물가상승률', '을', '느낀다']\n",
      "------------------\n",
      "vocabulary : {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
      "bag of words vector : [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "doc2 = \"소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.\"\n",
    "vocab, bow = build_bag_of_words(doc2)\n",
    "print(\"vocabulary :\", vocab)\n",
    "print(\"bag of words vector :\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "482e0bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다', '소비자', '는', '주로', '소비', '하는', '상품', '을', '기준', '으로', '물가상승률', '을', '느낀다']\n",
      "------------------\n",
      "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
      "bag of words vector : [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "doc3 = doc1 + '' + doc2\n",
    "vocab, bow = build_bag_of_words(doc3)\n",
    "print(\"vocabulary :\", vocab)\n",
    "print(\"bag of words vector :\", bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacb240",
   "metadata": {},
   "source": [
    "## CountVectorizer 클래스로 BoW만들기\n",
    "영어에 대해서 BoW해주는 클래스  \n",
    "띄어쓰기 정도만 단어를 구분하지만 영어에서는 문제 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd4c641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "bag of words vector :   (0, 4)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 0)\t1\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['you know I want your love. because I love you.']\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "print('bag of words vector :', vector.fit_transform(corpus))\n",
    "\n",
    "# 각 단어의 인덱스가 어떻게 부여되었는지를 출력\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d1c94",
   "metadata": {},
   "source": [
    "## 불용어를 제거한 BoW 만들기\n",
    "### (1) 사용자가 직접 정의한 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9554b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=['the', 'a', 'an', 'is', 'not'])\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4615eb",
   "metadata": {},
   "source": [
    "### (2) CountVectorizer에서 제공하는 자체 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bd1e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n",
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25eb36e",
   "metadata": {},
   "source": [
    "### (3) NLTK에서 지원하는 불용어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efd44df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "sw = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words=sw)\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766bbd7",
   "metadata": {},
   "source": [
    "# 문서단어행렬(DTM) 단어문서행렬(TDM)\n",
    "행에는 문서가, 열에는 단어의 종류가 들어간다. 표에는 단어의 빈도 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7308eadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 열기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('C:\\\\Users\\\\Owner\\\\Desktop\\\\khh\\\\SeoulICT\\\\220226\\\\imdb.xlsx', index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69728f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
